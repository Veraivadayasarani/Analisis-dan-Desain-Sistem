{
  "nodes": [
    {
      "id": "huggingFaceInference_LLMs_0",
      "position": {
        "x": 1518.461905407384,
        "y": 460.1427780676552
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInference_LLMs_0",
        "label": "HuggingFace Inference",
        "version": 2,
        "name": "huggingFaceInference_LLMs",
        "type": "HuggingFaceInference",
        "baseClasses": [
          "HuggingFaceInference",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around HuggingFace large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInference_LLMs_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "model",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "gpt2",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-model-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/gpt2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-endpoint-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "description": "Top Probability parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-topP-number"
          },
          {
            "label": "Top K",
            "name": "hfTopK",
            "type": "number",
            "step": 0.1,
            "description": "Top K parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-hfTopK-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-frequencyPenalty-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "model": "",
          "endpoint": "",
          "temperature": "",
          "maxTokens": "",
          "topP": "",
          "hfTopK": "",
          "frequencyPenalty": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInference_LLMs_0-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "huggingFaceInference_LLMs",
            "label": "HuggingFaceInference",
            "description": "Wrapper around HuggingFace large language models",
            "type": "HuggingFaceInference | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 577,
      "selected": false,
      "positionAbsolute": {
        "x": 1518.461905407384,
        "y": 460.1427780676552
      },
      "dragging": false
    },
    {
      "id": "huggingFaceInference_LLMs_1",
      "position": {
        "x": 983.4102320117518,
        "y": 671.9734909281398
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInference_LLMs_1",
        "label": "HuggingFace Inference",
        "version": 2,
        "name": "huggingFaceInference_LLMs",
        "type": "HuggingFaceInference",
        "baseClasses": [
          "HuggingFaceInference",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around HuggingFace large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInference_LLMs_1-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "model",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "gpt2",
            "optional": true,
            "id": "huggingFaceInference_LLMs_1-input-model-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/gpt2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInference_LLMs_1-input-endpoint-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_1-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_1-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "description": "Top Probability parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_1-input-topP-number"
          },
          {
            "label": "Top K",
            "name": "hfTopK",
            "type": "number",
            "step": 0.1,
            "description": "Top K parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_1-input-hfTopK-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_1-input-frequencyPenalty-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "huggingFaceInference_LLMs_1-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "model": "",
          "endpoint": "",
          "temperature": "",
          "maxTokens": "",
          "topP": "",
          "hfTopK": "",
          "frequencyPenalty": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInference_LLMs_1-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "huggingFaceInference_LLMs",
            "label": "HuggingFaceInference",
            "description": "Wrapper around HuggingFace large language models",
            "type": "HuggingFaceInference | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 577,
      "selected": false,
      "positionAbsolute": {
        "x": 983.4102320117518,
        "y": 671.9734909281398
      },
      "dragging": false
    },
    {
      "id": "openAI_0",
      "position": {
        "x": 476.17646275639197,
        "y": 495.81802725505315
      },
      "type": "customNode",
      "data": {
        "id": "openAI_0",
        "label": "OpenAI",
        "version": 4,
        "name": "openAI",
        "type": "OpenAI",
        "baseClasses": [
          "OpenAI",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around OpenAI large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo-instruct",
            "id": "openAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "openAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-topP-number"
          },
          {
            "label": "Best Of",
            "name": "bestOf",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-bestOf-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-presencePenalty-number"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-baseOptions-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "openAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo-instruct",
          "temperature": 0.7,
          "maxTokens": "",
          "topP": "",
          "bestOf": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "openAI_0-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable",
            "name": "openAI",
            "label": "OpenAI",
            "description": "Wrapper around OpenAI large language models",
            "type": "OpenAI | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 574,
      "selected": false,
      "positionAbsolute": {
        "x": 476.17646275639197,
        "y": 495.81802725505315
      },
      "dragging": false
    }
  ],
  "edges": []
}